{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO1JCeiWTx2I",
        "outputId": "52ec71a1-c50b-45c3-8f40-c4a014c06dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVoNOiJ6ubTO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1meXwE_ucGC",
        "outputId": "38a632b9-6486-4130-8737-781fc939134e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.8/dist-packages (4.3.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from pymongo) (2.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo\n",
        "!pip install nltk\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2VK95JBVy3tD"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "# file management\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "#file saving\n",
        "import json\n",
        "#utilities\n",
        "from nltk.util import ngrams\n",
        "from pymongo import MongoClient\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from itertools import islice\n",
        "\n",
        "\n",
        "import psutil\n",
        "from multiprocessing import Pool\n",
        "import multiprocessing\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UA-nCZXwUeYV"
      },
      "outputs": [],
      "source": [
        "WORKING_DIR = '/content/drive/MyDrive/generate_n_grams'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l6-vwz-tUmon"
      },
      "outputs": [],
      "source": [
        "file_name = WORKING_DIR + \"/wikimatrix.en\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQKBH0g7J9lF",
        "outputId": "8f757260-8def-4e2d-ee00-8f5938670abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NFx0bhtEQXl9"
      },
      "outputs": [],
      "source": [
        "def generate_directories():\n",
        "  dir_name= WORKING_DIR + '/ngrams_multiprocessing_nosave_benchmark/'\n",
        "  for i in range(2,7):\n",
        "    os.makedirs(dir_name + str(i))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gqVwgdYGRKsu"
      },
      "outputs": [],
      "source": [
        "generate_directories()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpJykB69cCHx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eaA4U6QccC-b"
      },
      "outputs": [],
      "source": [
        "def list_files(dir):                                                                                                  \n",
        "    r = []                                                                                                            \n",
        "    subdirs = [x[0] for x in os.walk(dir)]                                                                            \n",
        "    for subdir in subdirs:                                                                                            \n",
        "        files = os.walk(subdir).next()[2]                                                                             \n",
        "        if (len(files) > 0):                                                                                          \n",
        "            for file in files:                                                                                        \n",
        "                r.append(os.path.join(subdir, file))                                                                         \n",
        "    return r   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwMcAlDJasEc",
        "outputId": "4898e55a-0b88-4cb9-a8ec-046f2f9da8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', '3', '4', '5', '6']\n"
          ]
        }
      ],
      "source": [
        "dir_name=WORKING_DIR + '/ngrams_multiprocessing_nosave_benchmark/'\n",
        "dir_list = os.listdir(dir_name)\n",
        "print(dir_list)\n",
        "# f = []\n",
        "# for (dirpath, dirnames, filenames) in os.walk(dir_name):\n",
        "#     print(filenames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xPF5c0nDfocP"
      },
      "outputs": [],
      "source": [
        "def append_dict(list_of_counts):\n",
        "  counter_total = Counter({})\n",
        "  for dict_count in list_of_counts:\n",
        "     counter = Counter(dict_count)\n",
        "     counter_total += counter\n",
        "  return counter_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYce3R1WcrP-"
      },
      "outputs": [],
      "source": [
        "def process_files_dict(dir_name):\n",
        "  dir_list = os.listdir(dir_name)\n",
        "  for n_gram_dir in dir_list:\n",
        "    change_dir = dir_name + n_gram_dir\n",
        "    #os.chdir(change_dir)\n",
        "    files = [file for file in glob.glob(change_dir + '/' + \"*.json\")]\n",
        "    if len(files) > 1:\n",
        "      main_file_dir = change_dir + '/total_n_gram.json'\n",
        "      for file_name in files:\n",
        "        if file_name != main_file_dir:\n",
        "          main_json = open(main_file_dir, \"r\")\n",
        "          other_json = open(file_name, \"r\")\n",
        "          main_dict = json.loads(main_json.read())\n",
        "          other_dict = json.loads(other_json.read())\n",
        "          list_dicts = [main_dict, other_dict]\n",
        "          key_count = append_dict(list_dicts)\n",
        "          key_count = dict(key_count)\n",
        "          main_json.close()\n",
        "          other_json.close()\n",
        "          with open(main_file_dir, 'w') as fp:\n",
        "            json.dump(key_count, fp)\n",
        "          if os.path.exists(file_name):\n",
        "            os.remove(file_name)\n",
        "          else:\n",
        "            print(\"{} does not exist\".format(file_name))\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "peignaJEektX",
        "outputId": "c49f195d-ab8c-4253-f199-450cb9c2cca6"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-9801cf1760fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_files_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-68-a438dc4a064a>\u001b[0m in \u001b[0;36mprocess_files_dict\u001b[0;34m(dir_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmain_file_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m           \u001b[0mmain_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_file_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m           \u001b[0mother_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mmain_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/generate_n_grams/ngrams/2/total_n_gram.json'"
          ]
        }
      ],
      "source": [
        "process_files_dict(dir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6--zzVzkSxTF"
      },
      "outputs": [],
      "source": [
        "def get_dict(counter_item):\n",
        "  text= ' '.join(counter_item[0])\n",
        "  count = counter_item[1]\n",
        "  count_dict = {text: count}\n",
        "  return count_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMRxf_-7ngKZ"
      },
      "outputs": [],
      "source": [
        "def get_counts(counter):\n",
        "  reference_dict = {}\n",
        "  for item in counter.most_common():\n",
        "    text= ' '.join(item[0])\n",
        "    count = item[1]\n",
        "    if not reference_dict.get(text,\"\"):\n",
        "      reference_dict[text] = count\n",
        "  return reference_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvaWIG9Hpy5d"
      },
      "outputs": [],
      "source": [
        "def append_dict(list_of_counts):\n",
        "  counter_total = Counter({})\n",
        "  for dict_count in list_of_counts:\n",
        "     counter = Counter(dict_count)\n",
        "     counter_total += counter\n",
        "  return counter_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OulZAi2CqhiY"
      },
      "outputs": [],
      "source": [
        "def count_in_text(text ,store):\n",
        "  for i in range(2,7):\n",
        "    ngram_counts = Counter(ngrams(text.split(), i))\n",
        "    temp_dict = get_counts(ngram_counts)\n",
        "    store.get(i).append(temp_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ4dw_yBtc0K"
      },
      "outputs": [],
      "source": [
        "def chunks(data, SIZE=100000):\n",
        "    it = iter(data)\n",
        "    for i in range(0, len(data), SIZE):\n",
        "        yield {k:data[k] for k in islice(it, SIZE)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjdMmUnnUfGe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6YSsN31JtcS"
      },
      "outputs": [],
      "source": [
        "def count_in_text(text ,store):\n",
        "  for i in range(2,7):\n",
        "    ngram_counts = Counter(ngrams(text.split(), i))\n",
        "    temp_dict = get_counts(ngram_counts)\n",
        "    store.get(i).append(temp_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8DUAWvCRyLI"
      },
      "outputs": [],
      "source": [
        "def count_in_text_local(batch_num, text, dir_name_template):\n",
        "  for i in range(2,7):\n",
        "    ngram_counts = Counter(ngrams(text.split(), i))\n",
        "    temp_dict = get_counts(ngram_counts)\n",
        "    dir_name = dir_name_template + str(i)\n",
        "    with open(dir_name + '/{}.json'.format(batch_num), 'w') as fp:\n",
        "      json.dump(temp_dict, fp)\n",
        "    print('saved batch {batch_num} for {i} grams'.format(batch_num=batch_num, i=i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsXCq__B3hOU"
      },
      "outputs": [],
      "source": [
        "# def count_in_text_local(batch_num, text, dir_name_template):\n",
        "#   all_vars = [batch_num, text, dir_name_template]\n",
        "#   #pool = Pool(psutil.cpu_count(logical=False))\n",
        "#   def count_per_ngram(i):\n",
        "#     ngram_counts = Counter(ngrams(text.split(), i))\n",
        "#     temp_dict = get_counts(ngram_counts)\n",
        "#     dir_name = dir_name_template + str(i)\n",
        "#     with open(dir_name + '/{}.json'.format(batch_num), 'w') as fp:\n",
        "#       json.dump(temp_dict, fp)\n",
        "#     print('saved batch {batch_num} for {i} grams'.format(batch_num=batch_num, i=i))\n",
        "#   pool = multiprocessing.Pool(5)\n",
        "#   pool.map(count_per_ngram, range(2,7))\n",
        "#   pool.close()  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E52ItDvLAt0d"
      },
      "outputs": [],
      "source": [
        "def count_in_text_local(batch_num, text, dir_name_template, i):\n",
        "  ngram_counts = Counter(ngrams(text.split(), i))\n",
        "  temp_dict = get_counts(ngram_counts)\n",
        "  dir_name = dir_name_template + str(i)\n",
        "  with open(dir_name + '/{}.json'.format(batch_num), 'w') as fp:\n",
        "    json.dump(temp_dict, fp)\n",
        "  print('saved batch {batch_num} for {i} grams'.format(batch_num=batch_num, i=i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjpVLAaUZKDI"
      },
      "outputs": [],
      "source": [
        "# def aggregate_counts(save_dir):\n",
        "#   for i in range(2,7):\n",
        "#     #os.makedirs(dir_name + str(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzPq-YhlUp-S"
      },
      "outputs": [],
      "source": [
        "def get_ngram_dicts(filename, save_dir):\n",
        "  #ngram_dicts = {2: [], 3:[], 4:[], 5:[], 6:[]}\n",
        "  with open(filename) as fp:\n",
        "      text = ''\n",
        "      count = 0\n",
        "      segment_number = 1\n",
        "      grams_n = [2,3,4,5,6]\n",
        "      while True:\n",
        "        line = fp.readline()\n",
        "        if not line:\n",
        "          if segment_number == 1:\n",
        "            file_name = 'total_n_gram'\n",
        "            params = [(file_name, text, save_dir, num) for num in grams_n]\n",
        "            with Pool(processes=8) as pool:\n",
        "              pool.starmap(count_in_text_local, params)\n",
        "            #count_in_text_local('total_n_gram', text ,save_dir)\n",
        "          else:\n",
        "            file_name = segment_number\n",
        "            params = [(file_name, text, save_dir, num) for num in grams_n]\n",
        "            with Pool(processes=8) as pool:\n",
        "              pool.starmap(count_in_text_local, params)\n",
        "            #count_in_text_local(segment_number, text ,save_dir)\n",
        "          #process_files_dict(save_dir)\n",
        "          break\n",
        "        text += line\n",
        "        count += 1\n",
        "        if count == 100000:\n",
        "          if segment_number == 1:\n",
        "            file_name = 'total_n_gram'\n",
        "            params = [(file_name, text, save_dir, num) for num in grams_n]\n",
        "            with Pool(processes=8) as pool:\n",
        "              pool.starmap(count_in_text_local, params)\n",
        "            #count_in_text_local('total_n_gram', text ,save_dir)\n",
        "          else:\n",
        "            file_name = segment_number\n",
        "            params = [(file_name, text, save_dir, num) for num in grams_n]\n",
        "            with Pool(processes=8) as pool:\n",
        "              pool.starmap(count_in_text_local, params)\n",
        "            #count_in_text_local(segment_number, text ,save_dir)\n",
        "          #process_files_dict(save_dir)\n",
        "          count = 0\n",
        "          segment_number += 1 \n",
        "          text = ''\n",
        "\n",
        "      \n",
        "\n",
        "          \n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMMoVy8msfuZ"
      },
      "outputs": [],
      "source": [
        "def upload_ngram_dicts(ngram_dicts, mongodb_collections):\n",
        "  for index, key in enumerate(ngram_dicts):\n",
        "    key_count = append_dict(ngram_dicts[key])\n",
        "    key_count = dict(key_count)\n",
        "    count = 0\n",
        "    for item in chunks(key_count, 200000):\n",
        "      staging_item = {'part': count, 'counter': item}\n",
        "      mongodb_collections[index].insert_one(staging_item)\n",
        "      count+=1\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tizKF6hND7MW",
        "outputId": "26bb25c3-a8de-4923-8531-9d2ee476971a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_cores = multiprocessing.cpu_count()\n",
        "n_cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC8dgWPcxJeU"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  dir_name = WORKING_DIR + '/ngrams_multiprocessing_nosave_benchmark/'\n",
        "  get_ngram_dicts(file_name, dir_name)\n",
        "  #upload_ngram_dicts(ngram_dicts, collections)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0snPqR2uyAAg",
        "outputId": "2514cf2f-14f2-4c78-f592-0f83eacbe1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "process starting\n",
            "saved batch total_n_gram for 2 grams\n",
            "saved batch total_n_gram for 3 grams\n",
            "saved batch total_n_gram for 4 grams\n",
            "saved batch total_n_gram for 5 grams\n",
            "saved batch total_n_gram for 6 grams\n",
            "saved batch 2 for 2 grams\n",
            "saved batch 2 for 3 grams\n",
            "saved batch 2 for 4 grams\n",
            "saved batch 2 for 5 grams\n",
            "saved batch 2 for 6 grams\n",
            "saved batch 3 for 2 grams\n",
            "saved batch 3 for 3 grams\n",
            "saved batch 3 for 4 grams\n",
            "saved batch 3 for 5 grams\n",
            "saved batch 3 for 6 grams\n",
            "saved batch 4 for 2 grams\n",
            "saved batch 4 for 3 grams\n",
            "saved batch 4 for 4 grams\n",
            "saved batch 4 for 5 grams\n",
            "saved batch 4 for 6 grams\n",
            "29.716152667999268\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "print(\"process starting\")\n",
        "main()\n",
        "end = time.time()\n",
        "print(end - start)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tBdV7v4lyY4"
      },
      "outputs": [],
      "source": [
        "#26s"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}